# -*- coding: utf-8 -*-
"""
This script includes all CIFAR10 GAN models.
> DCGAN
> LSGAN
> WGAN

Each GAN model is its own class object. Each class has its own attributes.
- init: initialises the object
- build_generator: builds the generator model
- build_discriminator: builds the discriminator model
- train: the training loop for the particular type of model
- sample_imgs: produces images generated by the generator
- save_weights: saves the weights of the model
- load_weights: loads saved weights into the model
- get_features: provides the output of the discriminator at the feature level. Input: Image.

"""
#from __future__ import print_function, division

from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import Dense, Reshape, Flatten, Dropout, InputLayer
from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, LeakyReLU
from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, UpSampling3D
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras import Input

import tensorflow as tf
from tensorflow.keras import backend as K

import numpy as np
import time

class dcGanCifar10():
    def __init__(self):
        """Initialises necessasry values and objects"""
        # Input shape
        self.img_rows = 32
        self.img_cols = 32
        self.channels = 3
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.latent_dim = 100
        # Build and compile the discriminator
        self.discriminator = self.build_discriminator()
        # Build the generator
        self.generator = self.build_generator()


    def __repr__(self):

        description = "DCGAN model for CIFAR10 data."

        return description

    def build_generator(self):
        """ Builds the generator"""
        model = Sequential()

        model.add(Dense(256*4*4, activation='relu', input_dim = self.latent_dim))
        model.add(Reshape((4, 4, 256)))
        model.add(UpSampling2D())
        model.add(Conv2D(128, kernel_size = 4, padding = "same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Activation("relu"))
        model.add(UpSampling2D())
        model.add(Conv2D(64, kernel_size=4, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Activation("relu"))
        model.add(UpSampling2D())
        model.add(Conv2D(32, kernel_size=4, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Activation("relu"))
        model.add(Conv2D(self.channels, kernel_size=3, padding="same"))
        model.add(Activation("tanh"))
        assert model.output_shape == (None, self.img_cols, self.img_rows, self.channels)

        model.summary()

        return model

    def build_discriminator(self):
        """Builds the discriminator"""
        model = Sequential()

        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding="same"))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        model.add(Conv2D(64, kernel_size=3, strides=2, padding="same"))
        model.add(ZeroPadding2D(padding=((0,1),(0,1))))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        model.add(Conv2D(128, kernel_size=3, strides=2, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dropout(0.25))
        model.add(Conv2D(256, kernel_size=3, strides=2, padding="same"))
        model.add(BatchNormalization(momentum=0.8))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Flatten())
        #model.add(Dropout(0.25))
        model.add(Dense(1))

        model.summary()

        return model



    def train(self, epochs, BATCH_SIZE = 128):
        '''Trains the GAN model'''
        (X_train,_), (_,_) = cifar10.load_data()
        X_train = X_train.reshape(X_train.shape[0], self.img_rows, self.img_cols, self.channels).astype('float32')
        X_train = (X_train - 127.5) / 127.5

        BUFFER_SIZE = 60000

        train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

        self.losses = np.zeros((epochs*len(train_dataset), 3))

        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)

        generator_optimizer = Adam(0.0001)
        discriminator_optimizer = Adam(0.0001)

        def discriminator_loss(real_output, fake_output):
            real_loss = cross_entropy(tf.ones_like(real_output), real_output)
            fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
            total_loss = real_loss + fake_loss
            return total_loss

        def generator_loss(fake_output):
            return cross_entropy(tf.ones_like(fake_output), fake_output)

        def discriminator_accuracy(real_output, fake_output):
            preds = np.concatenate([real_output, fake_output])
            target = np.concatenate([np.ones_like(real_output), np.zeros_like(fake_output)])
            preds_int = (preds > 0.5).astype(int)
            target_int = (target > 0.5).astype(int)
            ans = np.sum(preds_int == target_int)/len(preds)
            return ans

        @tf.function
        def train_step(images):
            noise = tf.random.normal([BATCH_SIZE, self.latent_dim])

            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
                gen_imgs = self.generator(noise, training = True)

                real_output = self.discriminator(images, training = True)
                fake_output = self.discriminator(gen_imgs, training = True)

                gen_loss = generator_loss(fake_output)
                disc_loss = discriminator_loss(real_output, fake_output)

            grads_gen = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
            grads_disc = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)

            generator_optimizer.apply_gradients(zip(grads_gen, self.generator.trainable_variables))
            discriminator_optimizer.apply_gradients(zip(grads_disc, self.discriminator.trainable_variables))

            return disc_loss, gen_loss, real_output, fake_output


        for epoch in range(epochs):

            start = time.time()
            batch_size = len(train_dataset)
            batch = 0

            for image_batch in train_dataset:
                self.losses[batch_size*epoch + batch, 0] , self.losses[batch_size*epoch + batch, 1], real_output, fake_output = train_step(image_batch)
                disc_acc = discriminator_accuracy(real_output.numpy(), fake_output.numpy())
                self.losses[batch_size*epoch + batch, 2] = disc_acc
                print("%d [D loss: %f] [G loss: %f] [D acc: %f]" % (batch_size*epoch + batch, self.losses[batch_size*epoch + batch, 0], self.losses[batch_size*epoch + batch, 1], self.losses[batch_size*epoch + batch, 2]))
                batch = batch + 1


            print("%d [Batch time: %.3f]" % (epoch, time.time()-start))



    def save_weights(self, name):

        self.generator.save((name + "_dcgan_generator.h5"))
        self.discriminator.save((name +"_dcgan_discriminator.h5"))
        self.combined.save((name + "_dcgan_combined.h5"))

        return print("Model saved")

    def load_weights(self, name):

        self.generator = load_model((name + "_dcgan_generator.h5"))
        self.discriminator = load_model((name +"_dcgan_discriminator.h5"))
        self.combined = load_model((name + "_dcgan_combined.h5"))

        return print("Model loaded")

    def get_feature_encoder(self):

        transformer = Model(self.discriminator.inputs, self.discriminator.layers[-2].output)

        return transformer

    def save_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder.save((name + "_dcgan_encoder.h5"))

        return print("Encoder saved")

    def load_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder = load_model((name + "_dcgan_encoder.h5"))
        encoder.compile()

        return encoder

    def get_training_metrics(self):

        return self.losses, self.disc_acc




class lsGanCifar10():
    def __init__(self):
        # Input shape
        self.img_rows = 32
        self.img_cols = 32
        self.channels = 3
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.latent_dim = 100

        optimizer = Adam(0.0002, 0.5)

        # Build and compile the discriminator
        self.discriminator = self.build_discriminator()
        self.discriminator.compile(loss='mse',
            optimizer=optimizer,
            metrics=['accuracy'])

        # Build the generator
        self.generator = self.build_generator()

        # The generator takes noise as input and generated imgs
        z = Input(shape=(self.latent_dim,))
        img = self.generator(z)

        # For the combined model we will only train the generator
        self.discriminator.trainable = False

        # The valid takes generated images as input and determines validity
        valid = self.discriminator(img)

        # The combined model  (stacked generator and discriminator)
        # Trains generator to fool discriminator
        self.combined = Model(z, valid)
        # (!!!) Optimize w.r.t. MSE loss instead of crossentropy
        self.combined.compile(loss='mse', optimizer=optimizer)

    def build_generator(self, depth = 1):

        model = Sequential()

        model.add(Dense(depth*256, input_dim=self.latent_dim))
        model.add(LeakyReLU(alpha=0.2))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Dense(depth*512))
        model.add(LeakyReLU(alpha=0.2))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Dense(depth*1024))
        model.add(LeakyReLU(alpha=0.2))
        model.add(BatchNormalization(momentum=0.8))
        model.add(Dense(np.prod(self.img_shape), activation='tanh'))
        model.add(Reshape(self.img_shape))

        model.summary()

        noise = Input(shape=(self.latent_dim,))
        img = model(noise)

        return Model(noise, img)

    def build_discriminator(self, depth = 1):

        model = Sequential()

        model.add(Flatten(input_shape=self.img_shape))
        model.add(Dense(depth*512))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dense(depth*256))
        model.add(LeakyReLU(alpha=0.2))
        #model.add(Flatten())
        # (!!!) No softmax
        model.add(Dense(1))
        model.summary()

        return model

    def train(self, epochs, batch_size = 128, sample_interval = 50):

        (X_train,_), (_,_) = cifar10.load_data()

        X_train = X_train / 127.5 - 1
        X_train = np.expand_dims(X_train, axis = 3)

        valid = np.ones((batch_size, 1))
        fake = np.zeros((batch_size, 1))

        self.losses = np.zeros((epochs, 2))
        self.disc_acc = np.zeros((epochs, 1))

        for epoch in range(epochs):

            # Discriminator training
            idx = np.random.randint(0, X_train.shape[0], batch_size)
            imgs = X_train[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            gen_imgs = self.generator.predict(noise)

            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # Generator training
            g_loss = self.combined.train_on_batch(noise, valid)

            self.losses[epoch, 1] = d_loss[0]
            self.losses[epoch, 2] = g_loss
            self.disc_acc[epoch] = 100*d_loss[1]

            print("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))


        return print("Training complete!")

    def save_weights(self, name):

        self.generator.save((name + "_lsgan_generator.h5"))
        self.discriminator.save((name +"_lsgan_discriminator.h5"))
        self.combined.save((name + "_lsgan_combined.h5"))

        return print("Model saved")

    def load_weights(self, name):

        self.generator = load_model((name + "_lsgan_generator.h5"))
        self.discriminator = load_model((name +"_lsgan_discriminator.h5"))
        self.combined = load_model((name + "_lsgan_combined.h5"))

        return print("Model loaded")

    def get_feature_encoder(self):

        transformer = Model(self.discriminator.inputs, self.discriminator.layers[-2].output)

        return transformer

    def save_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder.save((name + "_lsgan_encoder.h5"))

        return print("Encoder saved")

    def load_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder = load_model((name + "_lsgan_encoder.h5"))
        encoder.compile()

        return encoder

    def get_training_metrics(self):

        return self.losses, self.disc_acc

"""
class wGanCifar10():
    def __init__(self):

        self.img_rows = 28

    def build_generator(self):

        model

    def build_critic(self):

        model

    def train(self):

        stuff

    def save_weights(self, name):

        self.generator.save((name + "_wgan_generator.h5"))
        self.discriminator.save((name +"_wgan_discriminator.h5"))
        self.combined.save((name + "_wgan_combined.h5"))

        return print("Model saved")

    def load_weights(self, name):

        self.generator.load_model((name + "_wgan_generator.h5"))
        self.discriminator.load_model((name +"_wgan_discriminator.h5"))
        self.combined.load_model((name + "_wgan_combined.h5"))

        return print("Model loaded")

    def get_feature_encoder(self):

        transformer = Model(self.discriminator.inputs, self.discriminator.layers[-2].output)

        return transformer

    def save_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder.save((name + "_wgan_encoder.h5"))

        return print("Encoder saved")

    def load_feature_encoder(self, name):

        encoder = self.get_feature_encoder()
        encoder = load_model((name + "_wgan_encoder.h5"))
        encoder.compile()

        return encoder
"""




class inception():
    """Feature Space using InceptionV3 model"""
    def __init__(self):
        self.upsampler = self.build_upsampler()
        self.inception = InceptionV3(include_top = False, input_shape = (96, 96, 3))

    def build_upsampler(self):
        upsampler = Sequential()
        upsampler.add(UpSampling2D(size = (3,3)))
        return upsampler


    def get_feature_encoder(self):

        img = Input(shape = (32, 32, 3))
        upimg = self.upsampler(img)
        fts = self.inception(upimg)
        sq_fts = tf.squeeze(fts)

        encoder = Model(img, sq_fts)

        return encoder

